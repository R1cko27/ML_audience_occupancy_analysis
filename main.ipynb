{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3f6e16",
   "metadata": {},
   "source": [
    "Подготавливаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d36046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 72, Val: 19\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_dataset():\n",
    "    base_path = 'hacaton'\n",
    "    images_dir = os.path.join(base_path, 'train', 'images')\n",
    "    labels_dir = os.path.join(base_path, 'train', 'labels')\n",
    "    \n",
    "    datasets_dir = os.path.join(base_path, 'datasets')\n",
    "    os.makedirs(os.path.join(datasets_dir, 'images', 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(datasets_dir, 'images', 'val'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(datasets_dir, 'labels', 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(datasets_dir, 'labels', 'val'), exist_ok=True)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(images_dir, file), \n",
    "                   os.path.join(datasets_dir, 'images', 'train', file))\n",
    "        label_file = os.path.splitext(file)[0] + '.txt'\n",
    "        if os.path.exists(os.path.join(labels_dir, label_file)):\n",
    "            shutil.copy(os.path.join(labels_dir, label_file), \n",
    "                       os.path.join(datasets_dir, 'labels', 'train', label_file))\n",
    "    \n",
    "    for file in val_files:\n",
    "        shutil.copy(os.path.join(images_dir, file), \n",
    "                   os.path.join(datasets_dir, 'images', 'val', file))\n",
    "        label_file = os.path.splitext(file)[0] + '.txt'\n",
    "        if os.path.exists(os.path.join(labels_dir, label_file)):\n",
    "            shutil.copy(os.path.join(labels_dir, label_file), \n",
    "                       os.path.join(datasets_dir, 'labels', 'val', label_file))\n",
    "    \n",
    "    print(f\"Train: {len(train_files)}, Val: {len(val_files)}\")\n",
    "    return datasets_dir\n",
    "\n",
    "datasets_dir = prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428dc168",
   "metadata": {},
   "source": [
    "Создаём YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d669e4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset YAML created!\n"
     ]
    }
   ],
   "source": [
    "dataset_yaml = f\"\"\"\n",
    "path: {os.path.abspath(datasets_dir)}\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: 1\n",
    "names: ['person']\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(datasets_dir, 'dataset.yaml'), 'w') as f:\n",
    "    f.write(dataset_yaml)\n",
    "\n",
    "print(\"Dataset YAML created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f13341",
   "metadata": {},
   "source": [
    "Дополняем датасет: Загружаем кастомные фотографии пустых аудиторий, фотографии локтей, стульев и СТОЯЧИХ людей (индефицируем их как преподователей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff636d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ignore_image\\\\chairs\\\\1.png', 'ignore_image\\\\chairs\\\\10.png', 'ignore_image\\\\chairs\\\\11.png', 'ignore_image\\\\chairs\\\\12.png', 'ignore_image\\\\chairs\\\\13.png', 'ignore_image\\\\chairs\\\\14.png', 'ignore_image\\\\chairs\\\\2.png', 'ignore_image\\\\chairs\\\\3.png', 'ignore_image\\\\chairs\\\\4.png', 'ignore_image\\\\chairs\\\\5.png', 'ignore_image\\\\chairs\\\\6.png', 'ignore_image\\\\chairs\\\\7.png', 'ignore_image\\\\chairs\\\\8.png', 'ignore_image\\\\chairs\\\\9.png', 'ignore_image\\\\elbows\\\\1.png', 'ignore_image\\\\elbows\\\\2.png', 'ignore_image\\\\elbows\\\\3.png', 'ignore_image\\\\elbows\\\\4.png']\n",
      "Негативные примеры добавлены!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def add_standing_people_to_negatives():\n",
    "    \n",
    "    datasets_dir = 'hacaton/datasets'\n",
    "    ignore_dir = 'ignore'\n",
    "    \n",
    "    neg_images_dir = os.path.join(datasets_dir, 'images', 'train')\n",
    "    neg_labels_dir = os.path.join(datasets_dir, 'labels', 'train')\n",
    "    \n",
    "    standing_people_images = []\n",
    "    if os.path.exists(ignore_dir):\n",
    "        for file in os.listdir(ignore_dir):\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                full_path = os.path.join(ignore_dir, file)\n",
    "                standing_people_images.append(full_path)\n",
    "    \n",
    "    for img_path in standing_people_images:\n",
    "        if os.path.exists(img_path):\n",
    "            img_name = os.path.basename(img_path)\n",
    "            name, ext = os.path.splitext(img_name)\n",
    "            new_img_name = f\"{name}_teach{ext}\"\n",
    "\n",
    "            shutil.copy(img_path, os.path.join(neg_images_dir, new_img_name))\n",
    "\n",
    "            label_name = f\"{name}_teach.txt\"\n",
    "            label_path = os.path.join(neg_labels_dir, label_name)\n",
    "            \n",
    "            with open(label_path, 'w') as f:\n",
    "                pass\n",
    "\n",
    "def add_negative_samples():\n",
    "    \n",
    "    datasets_dir = 'hacaton/datasets'\n",
    "\n",
    "    neg_images_dir = os.path.join(datasets_dir, 'images', 'train')\n",
    "    neg_labels_dir = os.path.join(datasets_dir, 'labels', 'train')\n",
    "    \n",
    "    negative_images = []\n",
    "    ignore_dir = 'ignore_image'\n",
    "\n",
    "    for root, dirs, files in os.walk(ignore_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                full_path = os.path.join(root, file)\n",
    "                negative_images.append(full_path)\n",
    "    \n",
    "    for img_path in negative_images:\n",
    "        if os.path.exists(img_path):\n",
    "            img_name = os.path.basename(img_path)\n",
    "            shutil.copy(img_path, os.path.join(neg_images_dir, img_name))\n",
    "            \n",
    "            # Создаем ПУСТОЙ .txt файл\n",
    "            label_name = os.path.splitext(img_name)[0] + '.txt'\n",
    "            label_path = os.path.join(neg_labels_dir, label_name)\n",
    "            \n",
    "            with open(label_path, 'w') as f:\n",
    "                pass\n",
    "    print(negative_images)\n",
    "    print(\"Негативные примеры добавлены!\")\n",
    "\n",
    "add_standing_people_to_negatives()\n",
    "add_negative_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39b3d62",
   "metadata": {},
   "source": [
    "Обучаем модель на базе yolov8n.\n",
    "Самая легкая модель для сохранения скорости"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f1843",
   "metadata": {},
   "source": [
    "Проверяем валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c192a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_improved_model():\n",
    "    model = YOLO('yolo/yolov8n.pt')\n",
    "    \n",
    "    results = model.train(\n",
    "        data=os.path.join(datasets_dir, 'dataset.yaml'),\n",
    "        epochs=100,\n",
    "        imgsz=1024,\n",
    "        batch=4,\n",
    "        device='cpu',\n",
    "        workers=0,\n",
    "        lr0=0.001,\n",
    "        lrf=0.01,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0005,\n",
    "        warmup_epochs=3.0,\n",
    "        warmup_momentum=0.8,\n",
    "        warmup_bias_lr=0.1,\n",
    "        box=7.5,\n",
    "        cls=0.5,\n",
    "        dfl=1.5,\n",
    "        pose=12.0,\n",
    "        kobj=1.0,\n",
    "        label_smoothing=0.0,\n",
    "        nbs=64,\n",
    "        hsv_h=0.015,\n",
    "        hsv_s=0.7,\n",
    "        hsv_v=0.4,\n",
    "        degrees=0.0,\n",
    "        translate=0.1,\n",
    "        scale=0.5,\n",
    "        shear=0.0,\n",
    "        perspective=0.0,\n",
    "        flipud=0.0,\n",
    "        fliplr=0.5,\n",
    "        mosaic=1.0,\n",
    "        mixup=0.0,\n",
    "        copy_paste=0.0,\n",
    "        auto_augment='randaugment',\n",
    "        erasing=0.4,\n",
    "        crop_fraction=1.0,\n",
    "        patience=20,\n",
    "        project='hacaton_results_improved',\n",
    "        name='yolov8s_improved_v2',\n",
    "        exist_ok=True,\n",
    "        single_cls=True,\n",
    "        optimizer='AdamW',\n",
    "        verbose=True,\n",
    "        seed=42,\n",
    "        deterministic=True,\n",
    "        plots=True,\n",
    "        save=True,\n",
    "        save_period=-1,\n",
    "        val=True,\n",
    "        amp=False\n",
    "    )\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "model_improved, results_improved = train_improved_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df739de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.229  Python-3.13.7 torch-2.8.0+cpu CPU (Intel Core 5 220H)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1539.9484.0 MB/s, size: 460.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ml\\hacaton\\datasets\\labels\\val.cache... 19 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 19/19 46.9Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.2it/s 4.1s1.2s\n",
      "                   all         19        941      0.785      0.631      0.709      0.332\n",
      "Speed: 1.2ms preprocess, 85.2ms inference, 0.0ms loss, 106.7ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\ml\\runs\\detect\\val2\u001b[0m\n",
      "Validation mAP50: 0.7087\n",
      "Validation mAP50-95: 0.3317\n"
     ]
    }
   ],
   "source": [
    "def validate_trained_model():\n",
    "    best_model_path = 'hacaton_results_improved/yolov8s_improved_v2/weights/best.pt'\n",
    "    \n",
    "    if os.path.exists(best_model_path):\n",
    "        model = YOLO(best_model_path)\n",
    "        \n",
    "        metrics = model.val(\n",
    "            data=os.path.join(datasets_dir, 'dataset.yaml'),\n",
    "            batch=4,\n",
    "            device='cpu',\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Validation mAP50: {metrics.box.map50:.4f}\")\n",
    "        print(f\"Validation mAP50-95: {metrics.box.map:.4f}\")\n",
    "        return metrics\n",
    "    else:\n",
    "        print(\"Trained model not found yet\")\n",
    "        return None\n",
    "\n",
    "metrics = validate_trained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b995be",
   "metadata": {},
   "source": [
    "Прогоняем модель по тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25532c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:   4%|▍         | 2/50 [00:00<00:16,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg: Лиц=18, Уникальных=18\n",
      "1.jpg: Лиц=16, Уникальных=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:   6%|▌         | 3/50 [00:01<00:14,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.jpg: Лиц=12, Уникальных=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:   8%|▊         | 4/50 [00:01<00:12,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.jpg: Лиц=122, Уникальных=122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  10%|█         | 5/50 [00:01<00:11,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.jpg: Лиц=15, Уникальных=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  12%|█▏        | 6/50 [00:01<00:11,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.jpg: Лиц=87, Уникальных=87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  14%|█▍        | 7/50 [00:01<00:11,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.jpg: Лиц=31, Уникальных=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  16%|█▌        | 8/50 [00:02<00:11,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.jpg: Лиц=66, Уникальных=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  18%|█▊        | 9/50 [00:02<00:10,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.jpg: Лиц=144, Уникальных=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  20%|██        | 10/50 [00:02<00:10,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.jpg: Лиц=32, Уникальных=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  22%|██▏       | 11/50 [00:03<00:09,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.jpg: Лиц=122, Уникальных=122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  24%|██▍       | 12/50 [00:03<00:09,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.jpg: Лиц=81, Уникальных=81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  26%|██▌       | 13/50 [00:03<00:08,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.jpg: Лиц=27, Уникальных=27\n",
      "20.jpg: Лиц=10, Уникальных=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  30%|███       | 15/50 [00:03<00:08,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.jpg: Лиц=110, Уникальных=110\n",
      "22.jpg: Лиц=43, Уникальных=43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  34%|███▍      | 17/50 [00:04<00:07,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.jpg: Лиц=37, Уникальных=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  36%|███▌      | 18/50 [00:04<00:08,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.jpg: Лиц=33, Уникальных=33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  38%|███▊      | 19/50 [00:05<00:08,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.jpg: Лиц=18, Уникальных=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  40%|████      | 20/50 [00:05<00:08,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.jpg: Лиц=59, Уникальных=59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  42%|████▏     | 21/50 [00:05<00:08,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.jpg: Лиц=46, Уникальных=46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  44%|████▍     | 22/50 [00:06<00:08,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.jpg: Лиц=53, Уникальных=53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  46%|████▌     | 23/50 [00:06<00:08,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.jpg: Лиц=87, Уникальных=87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  48%|████▊     | 24/50 [00:06<00:08,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.jpg: Лиц=22, Уникальных=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  50%|█████     | 25/50 [00:07<00:08,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.jpg: Лиц=6, Уникальных=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  52%|█████▏    | 26/50 [00:07<00:07,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.jpg: Лиц=108, Уникальных=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  54%|█████▍    | 27/50 [00:07<00:07,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.jpg: Лиц=41, Уникальных=41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  56%|█████▌    | 28/50 [00:07<00:06,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.jpg: Лиц=62, Уникальных=62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  58%|█████▊    | 29/50 [00:08<00:06,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.jpg: Лиц=161, Уникальных=161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  60%|██████    | 30/50 [00:08<00:05,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.jpg: Лиц=35, Уникальных=35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  62%|██████▏   | 31/50 [00:08<00:05,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.jpg: Лиц=57, Уникальных=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  64%|██████▍   | 32/50 [00:09<00:05,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.jpg: Лиц=37, Уникальных=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  66%|██████▌   | 33/50 [00:09<00:05,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.jpg: Лиц=11, Уникальных=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  68%|██████▊   | 34/50 [00:09<00:05,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.jpg: Лиц=133, Уникальных=133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  70%|███████   | 35/50 [00:10<00:04,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.jpg: Лиц=57, Уникальных=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  72%|███████▏  | 36/50 [00:10<00:04,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.jpg: Лиц=87, Уникальных=87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  74%|███████▍  | 37/50 [00:10<00:04,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.jpg: Лиц=11, Уникальных=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  76%|███████▌  | 38/50 [00:11<00:03,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.jpg: Лиц=103, Уникальных=103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  78%|███████▊  | 39/50 [00:11<00:03,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.jpg: Лиц=38, Уникальных=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  80%|████████  | 40/50 [00:11<00:02,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.jpg: Лиц=17, Уникальных=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  82%|████████▏ | 41/50 [00:11<00:02,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.jpg: Лиц=0, Уникальных=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  84%|████████▍ | 42/50 [00:12<00:02,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.jpg: Лиц=173, Уникальных=173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  86%|████████▌ | 43/50 [00:12<00:02,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.jpg: Лиц=30, Уникальных=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  88%|████████▊ | 44/50 [00:12<00:01,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.jpg: Лиц=57, Уникальных=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  90%|█████████ | 45/50 [00:13<00:01,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.jpg: Лиц=57, Уникальных=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  92%|█████████▏| 46/50 [00:13<00:01,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.jpg: Лиц=8, Уникальных=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  94%|█████████▍| 47/50 [00:13<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.jpg: Лиц=32, Уникальных=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  96%|█████████▌| 48/50 [00:13<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.jpg: Лиц=13, Уникальных=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing:  98%|█████████▊| 49/50 [00:14<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.jpg: Лиц=19, Уникальных=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble processing: 100%|██████████| 50/50 [00:14<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.jpg: Лиц=31, Уникальных=31\n",
      "\n",
      "Ensemble submission saved to submission_ensemble.csv\n",
      "Statistics:\n",
      "Min: 0, Max: 173, Mean: 53.50\n",
      "Total unique people detected: 2675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "def create_ensemble_submission():\n",
    "    model2 = YOLO('hacaton_results_improved/yolov8s_improved_v2/weights/best.pt')\n",
    "    test_images_dir = os.path.join('hacaton', 'test_images')\n",
    "    test_images = [f for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    output_dir = 'ensemble_results'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for image_file in tqdm(test_images, desc=\"Ensemble processing\"):\n",
    "        image_path = os.path.join(test_images_dir, image_file)\n",
    "        \n",
    "        original_image = cv2.imread(image_path)\n",
    "        original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results2 = model2.predict(\n",
    "            source=image_path,\n",
    "            conf=0.25,\n",
    "            iou=0.3,\n",
    "            imgsz=1024,\n",
    "            device='cpu', \n",
    "            verbose=False,\n",
    "            max_det=800,\n",
    "            augment=True,\n",
    "            save=False,\n",
    "            classes=[0],\n",
    "            agnostic_nms=False,\n",
    "            half=False,\n",
    "            nms=True,\n",
    "            mode='predict',\n",
    "        )\n",
    "\n",
    "        face_boxes = []\n",
    "        \n",
    "        for result in results2:\n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    conf = box.conf[0].cpu().numpy()\n",
    "                    face_boxes.append({\n",
    "                        'bbox': [x1, y1, x2, y2],\n",
    "                        'confidence': conf\n",
    "                    })\n",
    "        \n",
    "        unique_people_count = len(face_boxes)\n",
    "        \n",
    "        result_image = original_image_rgb.copy()\n",
    "        \n",
    "        # Визуализация лиц\n",
    "        for i, face in enumerate(face_boxes):\n",
    "            x1, y1, x2, y2 = map(int, face['bbox'])\n",
    "            confidence = face['confidence']\n",
    "            \n",
    "            color = (0, 255, 0)  # Зеленый для лиц\n",
    "            label = f\"Face {confidence:.3f}\"\n",
    "            \n",
    "            cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(result_image, label, (x1, y1-10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        # Статистика на изображении\n",
    "        cv2.putText(result_image, f\"Faces: {len(face_boxes)}\", (20, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(result_image, f\"Total unique: {unique_people_count}\", (20, 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        \n",
    "        # Сохраняем результат\n",
    "        result_filename = f\"{os.path.splitext(image_file)[0]}_ensemble.jpg\"\n",
    "        result_path = os.path.join(output_dir, result_filename)\n",
    "        cv2.imwrite(result_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # Записываем в CSV\n",
    "        img_id = os.path.splitext(image_file)[0]\n",
    "        results.append({'IMG_ID': img_id, 'label': unique_people_count})\n",
    "        \n",
    "        print(f\"{image_file}: Лиц={len(face_boxes)}, Уникальных={unique_people_count}\")\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    submission_path = 'submission_ensemble.csv'\n",
    "    df.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"\\nEnsemble submission saved to {submission_path}\")\n",
    "    print(\"Statistics:\")\n",
    "    print(f\"Min: {df['label'].min()}, Max: {df['label'].max()}, Mean: {df['label'].mean():.2f}\")\n",
    "    print(f\"Total unique people detected: {df['label'].sum()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "ensemble_result = create_ensemble_submission()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
